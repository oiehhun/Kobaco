{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from util import load_node_csv, load_edge_csv\n",
    "from model.light_gcn import LightGCN\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch_geometric.utils import structured_negative_sampling\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_sparse import SparseTensor\n",
    "\n",
    "import torch\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    pass\n",
    "\n",
    "args = Args()\n",
    "args.gpu = 'cuda:3'\n",
    "args.data_path = \"../data/kobaco.csv\"\n",
    "args.num_iters = 10000\n",
    "args.batch_size = 512\n",
    "args.lambda_val = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_mapping = load_node_csv(args.data_path, index_col='user_id')\n",
    "item_mapping = load_node_csv(args.data_path, index_col='item_id')\n",
    "\n",
    "num_users, num_items = len(user_mapping), len(item_mapping)\n",
    "\n",
    "train_edge_index = torch.load('../data/train_edge_index.pt').type(torch.long)\n",
    "test_edge_index = torch.load('../data/test_edge_index.pt').type(torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(args.gpu if torch.cuda.is_available() else 'cpu')\n",
    "model = LightGCN(num_users, num_items).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "train_sparse_edge_index = SparseTensor(row=train_edge_index[0], col=train_edge_index[1], sparse_sizes=(num_users + num_items, num_users + num_items)).to(device)\n",
    "test_sparse_edge_index = SparseTensor(row=test_edge_index[0], col=test_edge_index[1], sparse_sizes=(num_users + num_items, num_users + num_items)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function which random samples a mini-batch of positive and negative samples\n",
    "def sample_mini_batch(batch_size, edge_index):\n",
    "    \"\"\"Randomly samples indices of a minibatch given an adjacency matrix\n",
    "\n",
    "    Args:\n",
    "        batch_size (int): minibatch size\n",
    "        edge_index (torch.Tensor): 2 by N list of edges\n",
    "\n",
    "    Returns:\n",
    "        tuple: user indices, positive item indices, negative item indices\n",
    "    \"\"\"\n",
    "    edges = structured_negative_sampling(edge_index)\n",
    "    edges = torch.stack(edges, dim=0)\n",
    "    indices = random.choices(\n",
    "        [i for i in range(edges[0].shape[0])], k=batch_size)\n",
    "    batch = edges[:, indices]\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Cross Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label = torch.cat([torch.ones([args.batch_size]), torch.zeros([args.batch_size])]).to(device)\n",
    "\n",
    "# for n_iter in range(args.num_iters):\n",
    "#     model.train()\n",
    "#     batch = sample_mini_batch(args.batch_size, train_edge_index)\n",
    "#     # batch_idx = torch.randperm(args.batch_size*2)\n",
    "#     users, pos_items, neg_items = batch\n",
    "#     users = torch.cat([users]*2).to(device)\n",
    "#     items = torch.cat([pos_items, neg_items]).to(device)\n",
    "\n",
    "#     users_emb_final, users_emb_init, items_emb_final, items_emb_init = model.forward(train_sparse_edge_index)\n",
    "\n",
    "#     train_reg_loss = args.lambda_val * (users_emb_init.norm(2).pow(2) + items_emb_init.norm(2).pow(2))\n",
    "#     logits = torch.mul(users_emb_final[users], items_emb_final[items])\n",
    "#     logits = torch.sum(logits, dim=-1)\n",
    "#     # train_loss = model.bce_loss(logits[batch_idx], label[batch_idx]) + train_reg_loss\n",
    "#     train_loss = model.bce_loss(logits, label) + train_reg_loss\n",
    "    \n",
    "#     optimizer.zero_grad()\n",
    "#     train_loss.backward()\n",
    "#     optimizer.step()\n",
    "\n",
    "#     if n_iter % 200 == 0 and n_iter > 0:\n",
    "#         print(f\"[Epoch {n_iter}/{args.num_iters}] train_loss: {round(train_loss.item(), 5)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Personalized Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 100/10000] train_loss: -0.6930 | min_loss : 99999.0000\n",
      "[Epoch 200/10000] train_loss: -0.7045 | min_loss : -0.6930\n",
      "[Epoch 300/10000] train_loss: -0.7819 | min_loss : -0.7045\n",
      "[Epoch 400/10000] train_loss: -1.0355 | min_loss : -0.7819\n",
      "[Epoch 500/10000] train_loss: -1.7168 | min_loss : -1.0355\n",
      "[Epoch 600/10000] train_loss: -2.9225 | min_loss : -1.7168\n",
      "[Epoch 700/10000] train_loss: -4.1676 | min_loss : -2.9225\n",
      "[Epoch 800/10000] train_loss: -5.5043 | min_loss : -4.1676\n",
      "[Epoch 900/10000] train_loss: -7.6257 | min_loss : -5.5043\n",
      "[Epoch 1000/10000] train_loss: -10.0501 | min_loss : -7.6257\n",
      "[Epoch 1100/10000] train_loss: -12.2618 | min_loss : -10.0501\n",
      "[Epoch 1200/10000] train_loss: -12.6600 | min_loss : -12.2618\n",
      "[Epoch 1300/10000] train_loss: -16.1201 | min_loss : -12.6600\n",
      "[Epoch 1400/10000] train_loss: -18.7864 | min_loss : -16.1201\n",
      "[Epoch 1500/10000] train_loss: -20.5749 | min_loss : -18.7864\n",
      "[Epoch 1600/10000] train_loss: -24.0843 | min_loss : -20.5749\n",
      "[Epoch 1700/10000] train_loss: -27.6036 | min_loss : -24.0843\n",
      "[Epoch 1800/10000] train_loss: -29.3705 | min_loss : -27.6036\n",
      "[Epoch 1900/10000] train_loss: -34.1062 | min_loss : -29.3705\n",
      "[Epoch 2000/10000] train_loss: -36.5698 | min_loss : -34.1062\n",
      "[Epoch 2100/10000] train_loss: -38.8640 | min_loss : -36.5698\n",
      "[Epoch 2200/10000] train_loss: -45.2570 | min_loss : -38.8640\n",
      "[Epoch 2300/10000] train_loss: -48.2372 | min_loss : -45.2570\n",
      "[Epoch 2400/10000] train_loss: -53.6985 | min_loss : -48.2372\n",
      "[Epoch 2500/10000] train_loss: -53.8679 | min_loss : -53.6985\n",
      "[Epoch 2600/10000] train_loss: -57.8505 | min_loss : -53.8679\n",
      "[Epoch 2700/10000] train_loss: -64.1938 | min_loss : -57.8505\n",
      "[Epoch 2800/10000] train_loss: -68.4893 | min_loss : -64.1938\n",
      "[Epoch 2900/10000] train_loss: -70.6201 | min_loss : -68.4893\n",
      "[Epoch 3000/10000] train_loss: -77.0154 | min_loss : -70.6201\n",
      "[Epoch 3100/10000] train_loss: -80.2978 | min_loss : -77.0154\n",
      "[Epoch 3200/10000] train_loss: -91.3164 | min_loss : -80.2978\n",
      "[Epoch 3300/10000] train_loss: -95.3328 | min_loss : -91.3164\n",
      "[Epoch 3400/10000] train_loss: -93.2719 | min_loss : -95.3328\n",
      "[Epoch 3500/10000] train_loss: -103.1745 | min_loss : -95.3328\n",
      "[Epoch 3600/10000] train_loss: -108.4161 | min_loss : -103.1745\n",
      "[Epoch 3700/10000] train_loss: -112.4283 | min_loss : -108.4161\n",
      "[Epoch 3800/10000] train_loss: -116.3612 | min_loss : -112.4283\n",
      "[Epoch 3900/10000] train_loss: -126.3381 | min_loss : -116.3612\n",
      "[Epoch 4000/10000] train_loss: -130.6316 | min_loss : -126.3381\n",
      "[Epoch 4100/10000] train_loss: -139.6089 | min_loss : -130.6316\n",
      "[Epoch 4200/10000] train_loss: -141.5938 | min_loss : -139.6089\n",
      "[Epoch 4300/10000] train_loss: -145.7012 | min_loss : -141.5938\n",
      "[Epoch 4400/10000] train_loss: -156.1409 | min_loss : -145.7012\n",
      "[Epoch 4500/10000] train_loss: -156.7073 | min_loss : -156.1409\n",
      "[Epoch 4600/10000] train_loss: -169.2182 | min_loss : -156.7073\n",
      "[Epoch 4700/10000] train_loss: -172.1191 | min_loss : -169.2182\n",
      "[Epoch 4800/10000] train_loss: -176.5354 | min_loss : -172.1191\n",
      "[Epoch 4900/10000] train_loss: -183.4021 | min_loss : -176.5354\n",
      "[Epoch 5000/10000] train_loss: -186.7613 | min_loss : -183.4021\n",
      "[Epoch 5100/10000] train_loss: -191.2885 | min_loss : -186.7613\n",
      "[Epoch 5200/10000] train_loss: -207.0890 | min_loss : -191.2885\n",
      "[Epoch 5300/10000] train_loss: -221.1923 | min_loss : -207.0890\n",
      "[Epoch 5400/10000] train_loss: -221.7706 | min_loss : -221.1923\n",
      "[Epoch 5500/10000] train_loss: -225.9488 | min_loss : -221.7706\n",
      "[Epoch 5600/10000] train_loss: -242.2093 | min_loss : -225.9488\n",
      "[Epoch 5700/10000] train_loss: -225.2984 | min_loss : -242.2093\n",
      "[Epoch 5800/10000] train_loss: -245.4923 | min_loss : -242.2093\n",
      "[Epoch 5900/10000] train_loss: -255.4990 | min_loss : -245.4923\n",
      "[Epoch 6000/10000] train_loss: -259.4128 | min_loss : -255.4990\n",
      "[Epoch 6100/10000] train_loss: -273.2189 | min_loss : -259.4128\n",
      "[Epoch 6200/10000] train_loss: -287.7213 | min_loss : -273.2189\n",
      "[Epoch 6300/10000] train_loss: -285.2314 | min_loss : -287.7213\n",
      "[Epoch 6400/10000] train_loss: -276.0525 | min_loss : -287.7213\n",
      "[Epoch 6500/10000] train_loss: -286.0905 | min_loss : -287.7213\n",
      "[Epoch 6600/10000] train_loss: -301.1380 | min_loss : -287.7213\n",
      "[Epoch 6700/10000] train_loss: -335.6068 | min_loss : -301.1380\n",
      "[Epoch 6800/10000] train_loss: -308.3907 | min_loss : -335.6068\n",
      "[Epoch 6900/10000] train_loss: -325.4744 | min_loss : -335.6068\n",
      "[Epoch 7000/10000] train_loss: -351.0492 | min_loss : -335.6068\n",
      "[Epoch 7100/10000] train_loss: -354.9639 | min_loss : -351.0492\n",
      "[Epoch 7200/10000] train_loss: -355.7035 | min_loss : -354.9639\n",
      "[Epoch 7300/10000] train_loss: -370.3355 | min_loss : -355.7035\n",
      "[Epoch 7400/10000] train_loss: -370.4943 | min_loss : -370.3355\n"
     ]
    }
   ],
   "source": [
    "min_loss = 99999\n",
    "SAVE_DIR = '../output'\n",
    "MODEL_NAME = 'light-gcn'\n",
    "\n",
    "for n_iter in range(args.num_iters):\n",
    "    model.train()\n",
    "    batch = sample_mini_batch(args.batch_size, train_edge_index)\n",
    "    users, pos_items, neg_items = batch\n",
    "    users = torch.cat([users]*2).to(device)\n",
    "    items = torch.cat([pos_items, neg_items]).to(device)\n",
    "\n",
    "    # forward propagation\n",
    "    users_emb_final, users_emb_init, items_emb_final, items_emb_init = model.forward(train_sparse_edge_index)\n",
    "\n",
    "    # mini batching\n",
    "    users, pos_items, neg_items = batch\n",
    "    users, pos_items, neg_items = users.to(device), pos_items.to(device), neg_items.to(device)\n",
    "    users_emb_final, users_emb_init = users_emb_final[users], users_emb_init[users]\n",
    "    pos_items_emb_final, pos_items_emb_init = items_emb_final[pos_items], items_emb_init[pos_items]\n",
    "    neg_items_emb_final, neg_items_emb_init = items_emb_final[neg_items], items_emb_init[neg_items]\n",
    "\n",
    "    train_loss = model.bpr_loss(users_emb_final, users_emb_init, pos_items_emb_final, pos_items_emb_init, neg_items_emb_final, neg_items_emb_init, args.lambda_val)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    \n",
    "\n",
    "    if n_iter % 100 == 0 and n_iter > 0:\n",
    "        cur_loss = train_loss.item()\n",
    "        print(f\"[Epoch {n_iter}/{args.num_iters}] train_loss: {cur_loss:.4f} | min_loss : {min_loss:.4f}\")\n",
    "        if min_loss > cur_loss:\n",
    "            min_loss = train_loss\n",
    "            model.eval()\n",
    "            model.to('cpu')\n",
    "            torch.save(model.state_dict(), f'{SAVE_DIR}/model/{MODEL_NAME}.bin')\n",
    "            model.train()\n",
    "            model.to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GraphToken",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
