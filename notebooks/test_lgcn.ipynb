{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import torch\n",
    "from util import load_node_csv\n",
    "from model.light_gcn import LightGCN\n",
    "from util import load_jsonl\n",
    "from torch_sparse import SparseTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    pass\n",
    "\n",
    "args = Args()\n",
    "args.gpu = 'cuda:3'\n",
    "args.data_path = \"../data/kobaco.csv\"\n",
    "args.num_iters = 10000\n",
    "args.batch_size = 512\n",
    "args.lambda_val = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_mapping = load_node_csv(args.data_path, index_col='user_id')\n",
    "item_mapping = load_node_csv(args.data_path, index_col='item_id')\n",
    "\n",
    "num_users, num_items = len(user_mapping), len(item_mapping)\n",
    "\n",
    "train_edge_index = torch.load('../data/train_edge_index.pt').type(torch.long)\n",
    "test_edge_index = torch.load('../data/test_edge_index.pt').type(torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(args.gpu if torch.cuda.is_available() else 'cpu')\n",
    "model = LightGCN(num_users, num_items).to(device)\n",
    "\n",
    "train_sparse_edge_index = SparseTensor(row=train_edge_index[0], col=train_edge_index[1], sparse_sizes=(num_users + num_items, num_users + num_items)).to(device)\n",
    "test_sparse_edge_index = SparseTensor(row=test_edge_index[0], col=test_edge_index[1], sparse_sizes=(num_users + num_items, num_users + num_items)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_path):\n",
    "        self.data = load_jsonl(data_path)\n",
    "        self.input_text_list = self.set_input_text_list()\n",
    "        self.answer_list = self.set_answer_list()\n",
    "        self.continuous_prompt_input_list = self.set_continuous_prompt_input_list()\n",
    "\n",
    "    def set_input_text_list(self):\n",
    "        input_text_list = []\n",
    "        for data in self.data:\n",
    "            user = data['user_id']\n",
    "            prompt =f'사용자 {user}의 TV 프로그램 시청 기록:\\n'\n",
    "            for idx, item in enumerate(data['iteracted_items']):\n",
    "                prompt += f'{idx}. {item}\\n'\n",
    "            prompt +='\\n타겟 TV 프로그램:\\n* ' + data['target_item'] + '\\n\\n'\n",
    "            prompt += data['question']\n",
    "            input_text_list.append(prompt)\n",
    "        return input_text_list\n",
    "\n",
    "    def set_answer_list(self):\n",
    "        return [x['answer'] for x in self.data]\n",
    "    \n",
    "\n",
    "    def set_continuous_prompt_input_list(self):\n",
    "        # return [{'input_text_list':'\\n'.join([x['node_information'],x['edge_information']])} for x in self.data]\n",
    "        return\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_text_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_text_list[idx], self.answer_list[idx]\n",
    "\n",
    "class RecommendationDataset(Dataset):\n",
    "    def __init__(self, data_path, user_mapping, item_mapping):\n",
    "        self.user_mapping = user_mapping\n",
    "        self.item_mapping = item_mapping\n",
    "        super().__init__(data_path)\n",
    "        \n",
    "\n",
    "    def set_continuous_prompt_input_list(self):\n",
    "        continuous_prompt_input_list = []\n",
    "        for x in self.data:\n",
    "            interacted_items = list(map(lambda item:self.item_mapping[item], x['iteracted_items']))\n",
    "            target_item = [self.item_mapping[x['target_item']]]\n",
    "            item_ids = torch.Tensor(interacted_items+target_item).type(torch.long)\n",
    "            user_id = torch.Tensor([self.user_mapping[x['user_id']]]).type(torch.long)\n",
    "            continuous_prompt_input_list.append({'user_id':user_id, 'item_ids':item_ids})\n",
    "        return continuous_prompt_input_list\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_text_list[idx], self.continuous_prompt_input_list[idx], self.answer_list[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR = '../output'\n",
    "MODEL_NAME = 'light-gcn'\n",
    "\n",
    "model.load_state_dict(torch.load(f'{SAVE_DIR}/model/{MODEL_NAME}.bin'))\n",
    "test_dataset = RecommendationDataset('../data/test.jsonl', user_mapping, item_mapping)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "428607a354ba4e6a8e699aa91925eb24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5666 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "users_emb_final, _, items_emb_final, _ = model(train_sparse_edge_index)\n",
    "\n",
    "y_true, y_pred = [], []\n",
    "for input_text, continuous_prompt_input, answer_list in tqdm(test_dataloader):\n",
    "    with torch.no_grad():\n",
    "        user_emb = users_emb_final[continuous_prompt_input['user_id']][:,-1,:]\n",
    "        item_emb = items_emb_final[continuous_prompt_input['item_ids']][:,-1,:]\n",
    "        score = torch.mul(user_emb, item_emb)\n",
    "        score = torch.sum(score, dim=-1)\n",
    "        pred = torch.nn.functional.sigmoid(score)\n",
    "        y_pred.append(1 if pred >= 0.5 else 0)\n",
    "        y_true.append(1 if answer_list[0] == '예' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8206847864454642\n",
      "0.8168049044356293\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "print(accuracy)\n",
    "print(f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GraphToken",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
